---
title: "p8105_hw5_yx2507"
author: "Yuqing Xue"
date: "11/2/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)

set.seed(10)

```
# Problem 1
read in irsi data.
Write a function that takes a vector as an argument; replaces missing values using the rules defined above; and returns the resulting vector. Apply this function to the columns of iris_with_missing using a map statement.
```{r}

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))%>%
  janitor::clean_names()
```

```{r}
missing_value_imputation = function(x){
  if (is.numeric(x)) {
    x = replace_na(x, mean(x, na.rm = TRUE))
  } else if (is.character(x)) {
    x = replace_na(x, "virginica")
  }
}
iris_new = map_df(iris_with_missing,missing_value_imputation)
```
After filling the missing data, we can see that there is no `NA` in the dataset now.

# Problem 2

```{r}
study_data=
  list.files(path = "./data")
  
data_files =  data_frame(files = study_data) %>%  
  mutate(
    data = map(files, ~read_csv(str_c("./data/", .x))))%>%
      unnest(cols = data)%>%
   pivot_longer( 
    week_1:week_8,
    names_to = "week",
    values_to = "data"
  ) %>% 
  mutate(
    arm = str_extract(files, "[:lower:]{3}"),
    subject_id = str_extract(files, "\\d{2}")
  )%>%
   mutate(
    week=str_replace(week, "week_", ""),
    week=as.numeric(week),
    arm = recode(arm, "con" = "control",
                      "exp" = "experiment"))%>%
  select(arm, subject_id, week, everything(), -files)

plot_con=data_files%>%
  ggplot(aes(x=week, y=data, color= subject_id))+
  geom_line()+facet_grid(~arm)
plot_con
  
```

We can see from the graphs shown above. In control arm, there is no much difference of data value for every subjects and there is no much changes across time, while in experiment arm, we can see there is a trend of increasing data value for every subjects across time.

# Problem 3
```{r}
sim_regression=function(n=30, beta0 = 2, beta1 = 0) {
  
  sim_data = tibble(
    x = rnorm(30, mean = 0, sd = 1),
    y = beta0 + beta1* x + rnorm(n, 0, 50)
  )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  tibble(
    beta1_hat = coef(ls_fit)[2],
    p_value= broom::tidy(ls_fit)$p.value[2]
  )
 

}

```
rerun simulation using for loop:
```{r}
beta1_list= list(
  "beta1_0"= 0,
  "beta1_1"= 1,
  "beta1_2"= 2,
  "beta1_3"= 3,
  "beta1_4"= 4,
  "beta1_5"= 5,
  "beta1_6"= 6
)
output = vector("list", length = 7)
for (i in 1:7) {
  
  output[[i]] = rerun(10000, sim_regression(n=30, beta1 = beta1_list[[i]]))%>%
    bind_rows()
  
}

```

```{r}
plot_reject=vector("list", length= 7)

for (i in 1:7){
  plot_reject[[i]]=output[[i]]%>%
  mutate(reject=ifelse(p_value<0.05,1,0))%>%
    group_by(reject)%>%
    filter(reject == 1)%>%
    count()%>%
    mutate(reject_proportion=n/10000)
}

plot_df= bind_rows(plot_reject)%>%
  mutate(beta1=c(0,1,2,3,4,5,6))
  
  reject_plot=plot_df%>%
    ggplot(aes(x= beta1, y=reject_proportion))+
  geom_point()+
    geom_line()

reject_plot

```
we can tell from the plot that when effect size increase, which in this case means beta1 increases, the proportion of reject is increasing which means the power of the test is increasing too.

## make a plot shows beta1 and beta1_hat
```{r}
sim_results = 
  tibble(beta1=c(0,1,2,3,4,5,6)) %>% 
  mutate(
    estimate_dfs = map(output, bind_rows)) %>% 
  unnest(estimate_dfs)%>%
  group_by(beta1)%>%
  mutate(average_estimate=mean(beta1_hat))

plot_beta=sim_results%>%
  ggplot(aes(x=beta1, y=average_estimate, color= beta1))+
  geom_point()+geom_line()

plot_beta
```

## make a plot shows the average estimate for among rejection 
```{r}
sim_results_reject = 
  tibble(beta1=c(0,1,2,3,4,5,6)) %>% 
  mutate(
    estimate_dfs = map(output, bind_rows)) %>% 
  unnest(estimate_dfsï¼‰%>%
           filter(p_value<0.05)%>%
    group_by(beta1)%>%
      mutate(average_estimate_re=mean(beta1_hat))
    
    plot_beta_reject=sim_results_reject%>%
      ggplot(aes(x=beta1, y= average_estimate_re))+
      geom_point()+
      geom_line()
    
    plot_beta_reject
         
 
```

For the average beta1 estimate among rejection, we can tell that the estimate beta1 is not equal to true beta1. This is because when we reject the estimate beta and claim that it is significantly different from zero, the effect size is large. So the coefficient estimate given that we have enough evidence to reject the null hypothsis will be large values and is not equals to true estimate.
